{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Semantic Kernel\n",
    "\n",
    "## Theory Module\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3.8 or later\n",
    "- Basic understanding of Python programming\n",
    "- OpenAI API key or Azure OpenAI access\n",
    "- Semantic Kernel library installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - call this once at the beginning of the notebook to add the parent directory to the path\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "\n",
    "sys.path.append(grandparent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is Semantic Kernel?\n",
    "\n",
    "Semantic Kernel is an open-source SDK that integrates LLMs into applications. Think of it as a bridge between your application and AI models, providing a structured way to:\n",
    "\n",
    "- Create AI-powered functions\n",
    "- Combine AI capabilities with traditional programming\n",
    "- Manage context and memory\n",
    "- Orchestrate complex AI workflows\n",
    "\n",
    "Compared to langchain or llama-index Semantic Kernel focuses deeply on workflows.\n",
    "\n",
    "### Setting up the Kernel\n",
    "\n",
    "In Semantic Kernel all interactions with a LLM happens through a kernel.\n",
    "Let's connect to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai import OpenAIProtocol\n",
    "\n",
    "# Create a kernel - the central orchestrator in Semantic Kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Configure the kernel with an AI service\n",
    "kernel.add_text_completion_service(\n",
    "    \"gpt-4\",  # Service ID\n",
    "    \"OpenAI\"  # Service type\n",
    ")\n",
    "\n",
    "# Test the kernel\n",
    "print(\"Kernel initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key concepts to understand about the kernel:\n",
    "\n",
    "- It's your main entry point for all SK operations\n",
    "- Manages AI service connections\n",
    "- Orchestrates function execution\n",
    "- Handles memory and context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Skills\n",
    "\n",
    "\n",
    "Skills in Semantic Kernel are collections of related functions.\n",
    "\n",
    "There are two types of skills/functions:\n",
    "\n",
    "**Native Skills**: Traditional Python functions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathSkill:\n",
    "    \"\"\"A simple native skill for mathematical operations\"\"\"\n",
    "    \n",
    "    def add(self, a: float, b: float) -> float:\n",
    "        \"\"\"Adds two numbers together\"\"\"\n",
    "        return a + b\n",
    "    \n",
    "    def multiply(self, a: float, b: float) -> float:\n",
    "        \"\"\"Multiplies two numbers\"\"\"\n",
    "        return a * b\n",
    "\n",
    "# Register the skill with the kernel\n",
    "math_skill = kernel.import_skill(MathSkill(), \"math\")\n",
    "\n",
    "# Use the skill\n",
    "result = math_skill.add(5, 3)\n",
    "print(f\"5 + 3 = {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic Skills**: AI-powered functions defined by prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a semantic function\n",
    "prompt_template = \"\"\"\n",
    "Input: {{$input}}\n",
    "Task: Generate three creative names for a pet {{$animal_type}}.\n",
    "Requirements:\n",
    "- Names should be family-friendly\n",
    "- Each name should be unique\n",
    "- Include a brief explanation for each name\n",
    "\n",
    "Output your response in this format:\n",
    "1. [Name] - [Explanation]\n",
    "2. [Name] - [Explanation]\n",
    "3. [Name] - [Explanation]\n",
    "\"\"\"\n",
    "\n",
    "# Create the semantic function\n",
    "pet_names = kernel.create_semantic_function(\n",
    "    prompt_template,\n",
    "    function_name=\"generate_pet_names\",\n",
    "    description=\"Generates creative pet names\"\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "async def generate_names():\n",
    "    result = await pet_names.invoke(input=\"\", animal_type=\"cat\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course you can combine both types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessingSkill:\n",
    "    \"\"\"A skill for processing text\"\"\"\n",
    "    \n",
    "    def count_words(self, input: str) -> int:\n",
    "        \"\"\"Counts words in a text\"\"\"\n",
    "        return len(input.split())\n",
    "    \n",
    "    def format_results(self, count: int, summary: str) -> str:\n",
    "        \"\"\"Formats the analysis results\"\"\"\n",
    "        return f\"Word count: {count}\\nSummary: {summary}\"\n",
    "\n",
    "# Create a semantic function for summarization\n",
    "summarize_prompt = \"\"\"\n",
    "Input: {{$input}}\n",
    "Task: Create a concise one-sentence summary.\n",
    "\"\"\"\n",
    "\n",
    "summarize = kernel.create_semantic_function(\n",
    "    summarize_prompt,\n",
    "    function_name=\"summarize\"\n",
    ")\n",
    "\n",
    "# Register the native skill\n",
    "text_skill = kernel.import_skill(TextProcessingSkill(), \"text\")\n",
    "\n",
    "# Create a pipeline\n",
    "async def analyze_text(input_text: str):\n",
    "    # First, get the summary\n",
    "    summary = await summarize.invoke(input_text)\n",
    "    \n",
    "    # Count words in original text\n",
    "    word_count = text_skill.count_words(input_text)\n",
    "    \n",
    "    # Format results\n",
    "    return text_skill.format_results(word_count, str(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Memory\n",
    "\n",
    "Semantic Kernel provides built-in memory capabilities using embeddings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup memory\n",
    "from semantic_kernel.memory.memory_store import MemoryStore\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "\n",
    "memory_store = MemoryStore()\n",
    "memory = SemanticTextMemory(storage=memory_store)\n",
    "kernel.import_skill(memory, \"memory\")\n",
    "\n",
    "# Store information\n",
    "async def store_memory():\n",
    "    await memory.save_information(\n",
    "        collection=\"facts\",\n",
    "        id=\"fact1\",\n",
    "        text=\"Semantic Kernel was created by Microsoft.\",\n",
    "        description=\"Basic SK fact\"\n",
    "    )\n",
    "\n",
    "# Retrieve information\n",
    "async def recall_memory():\n",
    "    results = await memory.search(\"Who created Semantic Kernel?\")\n",
    "    print(results[0].text if results else \"No information found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Wrapping it up - Emoji Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmojiNarratorSkill:\n",
    "    \"\"\"A skill that translates complex narratives into and from emoji sequences\"\"\"\n",
    "    \n",
    "    def __init__(self, kernel: sk.Kernel):\n",
    "        # Create encoder function\n",
    "        encode_template = \"\"\"\n",
    "        Story: {{$story}}\n",
    "        Style: {{$style}}\n",
    "        \n",
    "        Transform this story into a sequence of emojis that:\n",
    "        1. Captures key plot points\n",
    "        2. Represents character emotions\n",
    "        3. Includes relevant symbols for setting\n",
    "        4. Uses emoji combinations for complex concepts\n",
    "        5. Maintains narrative flow\n",
    "        \n",
    "        Also provide a legend explaining your emoji choices.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create decoder function\n",
    "        decode_template = \"\"\"\n",
    "        Emoji sequence: {{$emoji_sequence}}\n",
    "        Genre: {{$genre}}\n",
    "        Tone: {{$tone}}\n",
    "        \n",
    "        Create a detailed story from these emojis that:\n",
    "        1. Interprets each emoji creatively\n",
    "        2. Builds a coherent narrative\n",
    "        3. Adds unexpected but logical connections\n",
    "        4. Includes dialogue and descriptions\n",
    "        5. Matches the specified genre and tone\n",
    "        \"\"\"\n",
    "        \n",
    "        self.encoder = kernel.create_semantic_function(encode_template)\n",
    "        self.decoder = kernel.create_semantic_function(decode_template)\n",
    "    \n",
    "    async def story_to_emoji(self, story: str, style: str = \"modern\"):\n",
    "        return await self.encoder.invoke(story=story, style=style)\n",
    "    \n",
    "    async def emoji_to_story(self, emoji_sequence: str, genre: str, tone: str):\n",
    "        return await self.decoder.invoke(\n",
    "            emoji_sequence=emoji_sequence,\n",
    "            genre=genre,\n",
    "            tone=tone\n",
    "        )\n",
    "\n",
    "# Example usage\n",
    "async def emoji_story_demo():\n",
    "    narrator = EmojiNarratorSkill(kernel)\n",
    "    \n",
    "    # Encode a story\n",
    "    original_story = \"A scientist accidentally creates a time machine but it only works on houseplants\"\n",
    "    emoji_version = await narrator.story_to_emoji(original_story, \"sci-fi comedy\")\n",
    "    \n",
    "    # Decode back to a different story\n",
    "    new_story = await narrator.emoji_to_story(\n",
    "        str(emoji_version),\n",
    "        genre=\"philosophical thriller\",\n",
    "        tone=\"mysterious\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Original: {original_story}\\nEmoji: {emoji_version}\\nNew Story: {new_story}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
