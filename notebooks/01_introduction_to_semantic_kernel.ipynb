{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Semantic Kernel\n",
    "\n",
    "## Theory Module\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3.8 or later\n",
    "- Basic understanding of Python programming\n",
    "- OpenAI API key or Azure OpenAI access\n",
    "- Semantic Kernel library installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - call this once at the beginning of the notebook to add the parent directory to the path\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "\n",
    "sys.path.append(grandparent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is Semantic Kernel?\n",
    "\n",
    "Semantic Kernel is an open-source SDK that integrates LLMs into applications. Think of it as a bridge between your application and AI models, providing a structured way to:\n",
    "\n",
    "- Create AI-powered functions\n",
    "- Combine AI capabilities with traditional programming\n",
    "- Manage context and memory\n",
    "- Orchestrate complex AI workflows\n",
    "\n",
    "Compared to langchain or llama-index Semantic Kernel focuses deeply on workflows.\n",
    "\n",
    "### Setting up the Kernel\n",
    "\n",
    "In Semantic Kernel all interactions with a LLM happens through a kernel.\n",
    "Let's connect to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai import OpenAIProtocol\n",
    "\n",
    "# Create a kernel - the central orchestrator in Semantic Kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Configure the kernel with an AI service\n",
    "kernel.add_text_completion_service(\n",
    "    \"gpt-4\",  # Service ID\n",
    "    \"OpenAI\"  # Service type\n",
    ")\n",
    "\n",
    "# Test the kernel\n",
    "print(\"Kernel initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key concepts to understand about the kernel:\n",
    "\n",
    "- It's your main entry point for all SK operations\n",
    "- Manages AI service connections\n",
    "- Orchestrates function execution\n",
    "- Handles memory and context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Core Components\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
