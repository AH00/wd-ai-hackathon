{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: A Bad Plan is better Than no Plan\n",
    "## Making AI Think and Remember\n",
    "\n",
    "### 1. Introduction to AI Planning\n",
    "One way to build apps with semantic kernel would be to use the concepts of module 1 and orchestrate those with code... But what if instead of you having to figure out how to chain functions together, the planner can look at all available tools and figure out the best way to solve a problem.\n",
    "\n",
    "### 2. Types of Planners\n",
    "\n",
    "#### 2.1 Sequential Planner\n",
    "The Sequential Planner is the LLM's recipe generator: It analyses tasks and generates a step-by-step plan. Conquer and divide!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The plan's steps are:\n",
      "- Writes a creative short story based on input. using WriterPlugin.WriteStory\n",
      "- √úbasetzt den Schoa√ü in z√ºnftigs Boaorisch. Nix f√ºr Prei√ün using WriterPlugin.GriabigerBoarischSprecha\n",
      "\n",
      "Final Result:\n",
      "Es war amal, in da louden Cyber-Metropole, Byte City g'nennt, do hot a g'schickte Programmiererin namens Nia glabt. Nia's Woit war a Labyrinth aus Logik-Gates und Code-Strukturen, a endloses Weidaus aus bin√§ren Landschaften. Ihre Aufgab war's, des digitale Reich mit Zeilen von Code z'besch√ºtzen und alles reibungslos laufa z'lassen. Eines Schicksals Mitternachts, wo der Neon-Schein ihrer Bildschirme ihre bescheidene Wohnung in elektrischem Blaufiaar tauchte, ist a r√§tselhafter Besucher aufgetaucht: a Bug.\n",
      "\n",
      "Des war net irgendein Bug; des war a rueg Phantom, das sich wie a fl√ºstender Geist durch ihren Code geschlichen hat und √ºberall Unfug und Verw√ºstung verursacht hat. Es hot im wichtigsten Teil ihra Projekts entsprocha ‚Äì a kompliziertes Algorithmus, der die verschl√ºsselten Kommunikations von Byte City‚Äôs Netzwerk stabilisieren sollt. Der Bug blieb verschwunden, hat in den Schatten ihrer Variablen gekichert und jeda Versuch, ihn ze fanga, verh√∂hnt.\n",
      "\n",
      "Nia's Monitore waren mit Streams von Konsolenprotokollen und Fehlermeldungen √ºberflutet, wie a unheilverk√ºndender Regen aus Hieroglyphen. Verzweiflung machte die Luft spr√∂de. Stundenlang is sie durch Schleifen und verschachtelte Funktionen navigiert, jede Zeile verfolgt, jede Bedingung seziert. Ihre Roboterkatze Pixel, die auf ihrem Schreibtisch lag, miaute leise, als wollt' sie moralische Unterst√ºtzung leisten.\n",
      "\n",
      "Der Uhrschlog drei und Nia's Augen brannten mit der Intensit√§t von tausend LEDs. Sie wusste, dass sie eine andere Herangehensweise versuchen musste. Zur√ºckgelehnt, schloss sie ihre Augen und lie√ü ihr Mind durch die immaterielle Landschaft ihres Codes schweifen. Sie stellte sich ihr Programm net als fade Zeilen von Syntax vor, sondern als a kompliziertes Tapet aus verwobenen F√§den.\n",
      "\n",
      "Dann hot sie a Eingebung, wie a pl√∂tzlicher Leuchtturm, der durch die D√§mmerung bricht. Sie erinert sich an a obskures St√ºck von alter Programmierer-Lore, a Gschicht aus den fr√ºhen Tagen der Ethernet-Zauberer: ‚ÄûDer Phantom-Bug versteckt sich oft in der kleinsten, am meisten √ºbersehnen Ecke, wo a einzelner Variable im dunklen Gang vom Code f√ºr an anderen gehalten werdn konnt.‚Äú\n",
      "\n",
      "Ihr Herz raste. Sie suchte hastig die versteckten Ecken ihres Codes ab, ihre Finger tanzten √ºber die Tastatur wie a Virtuose, der a digitale Symphonie spielt. Do war er, der spukhafte Fehler: a einfacher Tippfehler in an Variablennamen, der sich in an sonsta makellosen Funktion versteckte. Ihr Verdacht war richtig gwen.\n",
      "\n",
      "Bekannt f√ºr ihre Genauigkeit, hat sie net nur den Tippfehler behoben; sie hot den Abschnitt von Code √ºberarbeitet, dass er robust und elegant war, a echtes Wunderwerk der Programmierkunst. Mit a'm tief'n Atemzug hat Nia ihren Patch ausgef√ºhrt. Der Code wurde ohne Probleme kompiliert und lief geschmeidiger als je zuvor. Der Bug war besiegt, seine Boshaftigkeit l√∂ste sich in de Luft auf.\n",
      "\n",
      "Als das erste Licht des Morgens durch ihr Fenster schien, √ºberkam Nia a Welle von Triumph. Sie feierte mit Pixel, der ihr anerkennend zugurrte in Anzin auf ihren Sieg. Das verschl√ºsselte Netzwerk von Byte City blieb sicher, dank ihrer Hingabe.\n",
      "\n",
      "Es war a einziger Moment des Triumphs, a Erinnerung an die Sch√∂nheit und Komplexit√§t der digitalen Welt, die sie so liebte. Mit jedem Tastendr√ºck webte sie F√§den einer lebendigen Realit√§t innerhalb von Byte City, sorgte f√ºr Balance und Harmonie ‚Äì a digitale W√§chterin, immer bereit, die Phantomgeister im Syntax z'abwehren.\n",
      "\n",
      "Und so stelllte sich Nia dem neuen Tag, bereit, jedes R√§tsel zu knacken, das der Code als n√§chstes webte, √ºberzeugt von ihrem Verstand und den endlosen M√∂glichkeiten innerhalb der kaskadierenden Reiche von Byte City.\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.core_plugins import TextPlugin\n",
    "from semantic_kernel.planners import SequentialPlanner\n",
    "from semantic_kernel.functions import kernel_function, KernelFunctionFromPrompt\n",
    "\n",
    "# Set up kernel with OpenAI\n",
    "kernel = Kernel()\n",
    "service_id = \"default\"\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=service_id,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Add the built-in text plugin\n",
    "text_plugin = kernel.add_plugin(TextPlugin(), \"text\")\n",
    "\n",
    "# Create a custom semantic function for creative writing\n",
    "story_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"WriteStory\",\n",
    "    plugin_name=\"WriterPlugin\",\n",
    "    prompt=\"\"\"\n",
    "    Write a short story about: {{$input}}\n",
    "    Make it creative and engaging.\n",
    "    \"\"\",\n",
    "    description=\"Writes a creative short story based on input.\"\n",
    ")\n",
    "kernel.add_function(plugin_name=\"WriterPlugin\", function=story_function)\n",
    "\n",
    "# Create French translation function\n",
    "translate_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"GriabigerBoarischSprecha\",\n",
    "    plugin_name=\"WriterPlugin\",\n",
    "    prompt=\"\"\"\n",
    "    Translate the following text the very hard to understand bavarian german\n",
    "    from Bauer Huber and his cows who are selling you eggs on every occasion:\n",
    "    {{$input}}\n",
    "    \"\"\",\n",
    "    description=\"√úbasetzt den Schoa√ü in z√ºnftigs Boaorisch. Nix f√ºr Prei√ün\"\n",
    ")\n",
    "kernel.add_function(plugin_name=\"WriterPlugin\", function=translate_function)\n",
    "\n",
    "# Create our planner\n",
    "planner = SequentialPlanner(kernel, service_id)\n",
    "\n",
    "# Create a plan for a complex task\n",
    "ask = \"\"\"\n",
    "Write a story about a programmer solving a mysterious bug,\n",
    "translate it to crazy german bavarian slang\n",
    "\"\"\"\n",
    "\n",
    "plan = await planner.create_plan(goal=ask)\n",
    "\n",
    "print(\"The plan's steps are:\")\n",
    "for step in plan._steps:\n",
    "    print(f\"- {step.description} using {step.plugin_name}.{step.name}\")\n",
    "\n",
    "result = await plan.invoke(kernel)\n",
    "print(\"\\nFinal Result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Function Calling Stepwise Planner\n",
    "The Stepwise Planner can think and observe as it executes. It's particularly good at tasks that need reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../semantic-kernel/prompt_template_samples/Brainstorm\n",
      "üöó Adventure Planning AI üöó\n",
      "\n",
      "Q: Plan a road trip from New York to Boston. Calculate the driving distance and find the best time to start tomorrow morning.\n",
      "A: To plan your road trip from New York to Boston, you should start your trip tomorrow morning (Friday, 22 November, 2024) at around 8:00 AM for an optimal experience.\n",
      "\n",
      "Q: I want to go hiking for 3 hours. Suggest a starting time and calculate when I‚Äôll be back home.\n",
      "A: You can start hiking at 07:35:03 PM, and you'll be back home by 10:35:03 PM.\n",
      "\n",
      "Q: What is the sum of the distances 250 miles and 120 miles? Email this result to Sarah.\n",
      "A: The sum of the distances 250 miles and 120 miles is 370 miles.\n",
      "\n",
      "‚úÖ Adventure planning completed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.planners import FunctionCallingStepwisePlanner, FunctionCallingStepwisePlannerOptions\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "service_id = \"planner\"\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=service_id,\n",
    "    ),\n",
    ")\n",
    "plugin_path = os.path.join(\n",
    "    os.path.dirname(\"../semantic-kernel/prompt_template_samples/WriterPlugin\"),\n",
    "    \"Brainstorm\",\n",
    ")\n",
    "plugin_path = os.path.join(\n",
    "    os.path.dirname(\"../semantic-kernel/prompt_template_samples/EmailPlugin\"),\n",
    "    \"Brainstorm\",\n",
    ")\n",
    "print(plugin_path)\n",
    "# Add necessary plugins\n",
    "kernel.add_plugin(MathPlugin(), \"MathPlugin\")\n",
    "kernel.add_plugin(TimePlugin(), \"TimePlugin\")\n",
    "\n",
    "\n",
    "\n",
    "# Adventure planning questions\n",
    "questions = [\n",
    "    \"Plan a road trip from New York to Boston. Calculate the driving distance and find the best time to start tomorrow morning.\",\n",
    "    \"I want to go hiking for 3 hours. Suggest a starting time and calculate when I‚Äôll be back home.\",\n",
    "    \"What is the sum of the distances 250 miles and 120 miles? Email this result to Sarah.\",\n",
    "]\n",
    "\n",
    "# Planner configuration\n",
    "options = FunctionCallingStepwisePlannerOptions(\n",
    "    max_iterations=10,\n",
    "    max_tokens=4000,\n",
    ")\n",
    "planner = FunctionCallingStepwisePlanner(service_id=service_id, options=options)\n",
    "\n",
    "print(\"üöó Adventure Planning AI üöó\\n\")\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    result = await planner.invoke(kernel, question)\n",
    "    print(f\"A: {result.final_answer}\\n\")\n",
    "\n",
    "    # Uncomment this to see step-by-step function calls made by the planner\n",
    "    # print(f\"Chat history:\\n{result.chat_history}\\n\")\n",
    "\n",
    "print(\"‚úÖ Adventure planning completed!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Combining Planners and Memory\n",
    "\n",
    "Let's revisit memory!\n",
    "Finish implementing the next cell to import any kind of data you want into the memory (for example: docs or code from github, parse wikipedia articles etc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.memory import VolatileMemoryStore\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureTextEmbedding\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "\n",
    "from semantic_kernel.memory.volatile_memory_store import VolatileMemoryStore\n",
    "\n",
    "\n",
    "embedding_service_id = \"embeddings\"\n",
    "kernel.add_service(AzureTextEmbedding(service_id=embedding_service_id))\n",
    "\n",
    "# Set up memory system\n",
    "memory_store = VolatileMemoryStore()\n",
    "embeddings = AzureTextEmbedding(\n",
    "    service_id=embedding_service_id\n",
    ")\n",
    "memory = SemanticTextMemory(memory_store, embeddings)\n",
    "\n",
    "# TODO: Add some data to the memory\n",
    "\n",
    "# TODO: Query the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic Skills**: AI-powered functions defined by prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Web Research Assistant with Semantic Kernel üîç\n",
      "\n",
      "\n",
      "Research Task: \n",
      "    Research the latest developments in quantum computing.\n",
      "    Focus on recent breakthroughs in error correction.\n",
      "    Analyze the information and create a summary.\n",
      "    \n",
      "\n",
      "Starting research process...\n",
      "Error during research: 'str' object is not callable\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Research Task: \n",
      "    Find information about artificial intelligence in healthcare.\n",
      "    Focus on recent applications in diagnostic imaging.\n",
      "    Create a summary of the findings.\n",
      "    \n",
      "\n",
      "Starting research process...\n",
      "Error during research: 'str' object is not callable\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/blr1szn11g93yjfzy1y0r6tw0000gn/T/ipykernel_18551/251098218.py:200: RuntimeWarning: coroutine 'FunctionCallingStepwisePlanner.invoke' was never awaited\n",
      "  await conduct_research(kernel, task)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from typing import Annotated\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.memory import SemanticTextMemory\n",
    "from semantic_kernel.planners import FunctionCallingStepwisePlanner, FunctionCallingStepwisePlannerOptions\n",
    "from semantic_kernel.functions import kernel_function, KernelFunctionFromPrompt\n",
    "from websearch import WebSearch\n",
    "\n",
    "class WebResearchPlugin:\n",
    "    \"\"\"Plugin for web research capabilities\"\"\"\n",
    "\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"SearchWeb\",\n",
    "        description=\"Searches the web using DuckDuckGo and returns relevant URLs\"\n",
    "    )\n",
    "    def search_web(\n",
    "        self,\n",
    "        query: Annotated[str, \"a query to search the web\"]\n",
    "    ) -> Annotated[str, \"a json result of duckduckgo search\"]:\n",
    "        print(f\"Searching the web for: {query}\")\n",
    "        \n",
    "        web = WebSearch(query)\n",
    "        result = []\n",
    "        for i, page in enumerate(web.pages):\n",
    "            if i >= 5:\n",
    "                break\n",
    "            print(f\"Visiting: {page}\")\n",
    "            result.append(str(page))\n",
    "\n",
    "        return json.dumps(result)\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"ExtractContent\",\n",
    "        description=\"Extracts main content from a webpage\"\n",
    "    )\n",
    "    def extract_content(\n",
    "        self,\n",
    "        url: Annotated[str, \"the webpage URL to extract content from\"]\n",
    "    ) -> str:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            for element in soup(['script', 'style', 'nav', 'header', 'footer']):\n",
    "                element.decompose()\n",
    "            \n",
    "            text = soup.get_text(separator=' ', strip=True)\n",
    "            text = text[:2000] + \"...\" if len(text) > 2000 else text\n",
    "            print(f\"Extracted content: {text}\")\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting content: {str(e)}\"\n",
    "\n",
    "class ResearchPlugin:\n",
    "    \"\"\"Plugin for analyzing and summarizing research\"\"\"\n",
    "    \n",
    "    def __init__(self, memory: SemanticTextMemory):\n",
    "        self.memory = memory\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"SaveToMemory\",\n",
    "        description=\"Saves research information to semantic memory\"\n",
    "    )\n",
    "    async def save_to_memory(\n",
    "        self,\n",
    "        content: Annotated[str, \"the content to save to memory\"],\n",
    "        topic: Annotated[str, \"the research topic for categorization\"]\n",
    "    ) -> str:\n",
    "        try:\n",
    "            await self.memory.save_information(\n",
    "                collection=\"research_data\",\n",
    "                text=content,\n",
    "                description=f\"Research on {topic}\",\n",
    "                additional_metadata={\"topic\": topic}\n",
    "            )\n",
    "            return \"Content saved to memory successfully\"\n",
    "        except Exception as e:\n",
    "            return f\"Error saving to memory: {str(e)}\"\n",
    "\n",
    "async def setup_kernel_and_memory():\n",
    "    kernel = Kernel()\n",
    "    \n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    embedding_service_id = \"embeddings\"\n",
    "    kernel.add_service(AzureTextEmbedding(service_id=embedding_service_id))\n",
    "\n",
    "    memory_store = VolatileMemoryStore()\n",
    "    embeddings = AzureTextEmbedding(\n",
    "        service_id=embedding_service_id\n",
    "    )\n",
    "    memory = SemanticTextMemory(memory_store, embeddings)\n",
    "\n",
    "    kernel.add_plugin(WebResearchPlugin(), \"web\")\n",
    "    kernel.add_plugin(ResearchPlugin(memory), \"research\")\n",
    "\n",
    "    analyze_function = KernelFunctionFromPrompt(\n",
    "        function_name=\"AnalyzeContent\",\n",
    "        plugin_name=\"ResearchPlugin\",\n",
    "        prompt=\"\"\"\n",
    "        Content: {{$input}}\n",
    "        \n",
    "        Analyze this content and extract key points. Focus on:\n",
    "        1. Main concepts and ideas\n",
    "        2. Key findings or statements\n",
    "        3. Important relationships\n",
    "        4. Credibility of information\n",
    "        \n",
    "        Format your response as bullet points.\n",
    "        \"\"\",\n",
    "        description=\"Analyzes and extracts key points from content.\"\n",
    "    )\n",
    "\n",
    "    # Fixed the recall syntax in the prompt\n",
    "    summarize_function = KernelFunctionFromPrompt(\n",
    "        function_name=\"CreateSummary\",\n",
    "        plugin_name=\"ResearchPlugin\",\n",
    "        prompt=\"\"\"{{$research_data $topic}}\n",
    "        Research Topic: {{$topic}}\n",
    "        Collected Information:\n",
    "        \n",
    "        Create a comprehensive summary that:\n",
    "        1. Synthesizes the main findings\n",
    "        2. Highlights key agreements and contradictions\n",
    "        3. Identifies gaps in the information\n",
    "        4. Suggests areas for further research\n",
    "        \n",
    "        Keep the summary clear and well-structured.\n",
    "\n",
    "        \n",
    "        \"\"\",\n",
    "        description=\"Creates a summary from collected research.\"\n",
    "    )\n",
    "\n",
    "    kernel.add_function(plugin_name=\"ResearchPlugin\", function=analyze_function)\n",
    "    kernel.add_function(plugin_name=\"ResearchPlugin\", function=summarize_function)\n",
    "\n",
    "    return kernel\n",
    "\n",
    "async def conduct_research(kernel: Kernel, task: str):\n",
    "    planner = FunctionCallingStepwisePlanner(\n",
    "        service_id=\"default\",\n",
    "        options=FunctionCallingStepwisePlannerOptions(\n",
    "            max_iterations=15,\n",
    "            max_tokens=4000,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    try:\n",
    "        print(f\"\\nResearch Task: {task}\\n\")\n",
    "        print(\"Starting research process...\")\n",
    "        \n",
    "        result = planner.invoke(kernel, task)\n",
    "        planner.generate_plan_yaml(\"research_plan.yaml\")\n",
    "\n",
    "        await result\n",
    "        print(\"\\nResearch Results:\")\n",
    "        print(result.final_answer)\n",
    "        \n",
    "        print(\"\\nThought Process:\")\n",
    "        for thought in result.chat_history:\n",
    "            print(f\"- {thought}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during research: {str(e)}\")\n",
    "\n",
    "# Example research tasks\n",
    "research_tasks = [\n",
    "    \"\"\"\n",
    "    Research the latest developments in quantum computing.\n",
    "    Focus on recent breakthroughs in error correction.\n",
    "    Analyze the information and create a summary.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Find information about artificial intelligence in healthcare.\n",
    "    Focus on recent applications in diagnostic imaging.\n",
    "    Create a summary of the findings.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "print(\"üîç Web Research Assistant with Semantic Kernel üîç\\n\")\n",
    "\n",
    "# Setup kernel and memory\n",
    "kernel = await setup_kernel_and_memory()\n",
    "\n",
    "# Process each research task\n",
    "for task in research_tasks:\n",
    "    await conduct_research(kernel, task)\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Practices\n",
    "\n",
    "\n",
    "Always provide clear, specific goals\n",
    "Include error handling\n",
    "Monitor plan execution steps\n",
    "Validate results at each stage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
